# Temporalise - END-TO-END SENTENCE-LEVEL LIPREADING

Temporalize is a model that translates a sequence of video frames of varying lengths into text. It incorporates spatiotemporal convolutions, a recurrent neural network, and connectionist temporal classification loss, all trained as a cohesive unit. To our knowledge, Temporalize is the first end-to-end model capable of interpreting entire sentences from visual speech cues, learning both time-based visual features and the sequence model simultaneously. On the GRID dataset, Temporalize achieves 95.2% accuracy in a task involving sentence-level lipreading with overlapping speakers, surpassing the performance of experienced human lipreaders.

![image](https://github.com/arjun-unx/Temporalise/assets/84034246/d1b7b24f-35b1-4489-8b43-e0b6307e44a1)


https://github.com/arjun-unx/Temporalise/assets/84034246/61d44808-0fc0-41f3-9691-6a19e3e9ee92

